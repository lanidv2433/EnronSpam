{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66da0184-f495-4bf2-9bca-4c0948bca3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import re                                            \n",
    "import os\n",
    "\n",
    "import time\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74872e8e-4dae-4a86-be11-4dca6c074379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Path to clean data\n",
    "cleaned_data_path = 'cleaned_enron_spam_data.csv'\n",
    "\n",
    "# Check if the cleaned data already exists\n",
    "if not os.path.exists(cleaned_data_path):\n",
    "    # Load the original dataset\n",
    "    data = pd.read_csv('enron_spam_data.csv')\n",
    "\n",
    "    # Function to clean text\n",
    "    def clean_text(text):\n",
    "        if pd.notna(text):\n",
    "            # Remove non-alphanumeric characters\n",
    "            text = re.sub(r'[^a-zA-Z0-9]', ' ', text)\n",
    "            # Convert text to lower case\n",
    "            text = text.lower()\n",
    "            # Reduce multiple spaces to a single space\n",
    "            text = re.sub(r'\\s+', ' ', text)\n",
    "        return text\n",
    "\n",
    "    # Apply the clean_text function to 'Subject' and 'Message' columns\n",
    "    data['Subject'] = data['Subject'].apply(clean_text)\n",
    "    data['Message'] = data['Message'].apply(clean_text)\n",
    "\n",
    "    # Overwrite the original data file\n",
    "    data.to_csv(cleaned_data_path, index=False)\n",
    "else:\n",
    "    data = pd.read_csv(cleaned_data_path)\n",
    "    print(\"Cleaned data loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3225221-92a1-47e4-8044-ad343845b304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d4e1b75-cfb7-4511-9a3b-390677e10f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dfbeed7-6e85-4e0f-8ac1-d5196407f5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = data.iloc[19,2]\n",
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13681440-74eb-45c3-99e4-60710641dd2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message ID</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Message</th>\n",
       "      <th>Spam/Ham</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[christmas, tree, farm, pictures]</td>\n",
       "      <td>[]</td>\n",
       "      <td>ham</td>\n",
       "      <td>1999-12-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[vastar, resources, inc]</td>\n",
       "      <td>[gary, production, from, the, high, island, la...</td>\n",
       "      <td>ham</td>\n",
       "      <td>1999-12-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[calpine, daily, gas, nomination]</td>\n",
       "      <td>[calpine, daily, gas, nomination, 1, doc]</td>\n",
       "      <td>ham</td>\n",
       "      <td>1999-12-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[re, issue]</td>\n",
       "      <td>[fyi, see, note, below, already, done, stella,...</td>\n",
       "      <td>ham</td>\n",
       "      <td>1999-12-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[meter, 7268, nov, allocation]</td>\n",
       "      <td>[fyi, forwarded, by, lauri, a, allen, hou, ect...</td>\n",
       "      <td>ham</td>\n",
       "      <td>1999-12-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Message ID                            Subject  \\\n",
       "0           0  [christmas, tree, farm, pictures]   \n",
       "1           1           [vastar, resources, inc]   \n",
       "2           2  [calpine, daily, gas, nomination]   \n",
       "3           3                        [re, issue]   \n",
       "4           4     [meter, 7268, nov, allocation]   \n",
       "\n",
       "                                             Message Spam/Ham        Date  \n",
       "0                                                 []      ham  1999-12-10  \n",
       "1  [gary, production, from, the, high, island, la...      ham  1999-12-13  \n",
       "2          [calpine, daily, gas, nomination, 1, doc]      ham  1999-12-14  \n",
       "3  [fyi, see, note, below, already, done, stella,...      ham  1999-12-14  \n",
       "4  [fyi, forwarded, by, lauri, a, allen, hou, ect...      ham  1999-12-14  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the 'Subject' and 'Message' into lists of words, or use an empty list if the value is missing\n",
    "data['Subject'] = data['Subject'].apply(lambda x: x.split() if isinstance(x, str) else [])\n",
    "data['Message'] = data['Message'].apply(lambda x: x.split() if isinstance(x, str) else [])\n",
    "\n",
    "# Display the updated DataFrame to verify the changes\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d023505-0df0-4772-81f5-e722fb1f37e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = data.iloc[19,2]\n",
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5dbd0f3e-9f21-4b41-998a-fd61f67aa164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming 'Spam/Ham' is the column with spam or ham labels\n",
    "# category_counts = data['Spam/Ham'].value_counts()\n",
    "\n",
    "# # Calculate the total number of messages\n",
    "# total_messages = len(data)\n",
    "\n",
    "# # Calculate the a priori probabilities\n",
    "# p_ham = category_counts['ham'] / total_messages\n",
    "# p_spam = category_counts['spam'] / total_messages\n",
    "\n",
    "# # Print the probabilities\n",
    "# print(f\"Probability of Ham: {p_ham}\")\n",
    "# print(f\"Probability of Spam: {p_spam}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56513b9d-a009-48e8-870c-56e58e0d2b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 154326\n",
      "the: 288613\n",
      "to: 210628\n",
      "and: 155693\n",
      "of: 147052\n",
      "a: 116803\n",
      "in: 105622\n",
      "for: 80834\n",
      "you: 80025\n",
      "is: 70751\n",
      "this: 63159\n"
     ]
    }
   ],
   "source": [
    "# Initialize a Counter to hold word frequencies\n",
    "vocabulary = Counter()\n",
    "\n",
    "# Iterate over each list in the 'Message' column\n",
    "for message_list in data['Message']:\n",
    "    vocabulary.update(message_list)\n",
    "\n",
    "# Display the size of the vocabulary and some sample words with their counts\n",
    "print(f\"Vocabulary Size: {len(vocabulary)}\")\n",
    "\n",
    "# Print the 10 most common words\n",
    "for word, count in vocabulary.most_common(10):\n",
    "    print(f\"{word}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6f36614-9b6c-48ab-a17f-520b0bcc171c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message ID</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Message</th>\n",
       "      <th>Spam/Ham</th>\n",
       "      <th>Date</th>\n",
       "      <th>Message_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[christmas, tree, farm, pictures]</td>\n",
       "      <td>[]</td>\n",
       "      <td>ham</td>\n",
       "      <td>1999-12-10</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[vastar, resources, inc]</td>\n",
       "      <td>[gary, production, from, the, high, island, la...</td>\n",
       "      <td>ham</td>\n",
       "      <td>1999-12-13</td>\n",
       "      <td>gary production from the high island larger bl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[calpine, daily, gas, nomination]</td>\n",
       "      <td>[calpine, daily, gas, nomination, 1, doc]</td>\n",
       "      <td>ham</td>\n",
       "      <td>1999-12-14</td>\n",
       "      <td>calpine daily gas nomination 1 doc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[re, issue]</td>\n",
       "      <td>[fyi, see, note, below, already, done, stella,...</td>\n",
       "      <td>ham</td>\n",
       "      <td>1999-12-14</td>\n",
       "      <td>fyi see note below already done stella forward...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[meter, 7268, nov, allocation]</td>\n",
       "      <td>[fyi, forwarded, by, lauri, a, allen, hou, ect...</td>\n",
       "      <td>ham</td>\n",
       "      <td>1999-12-14</td>\n",
       "      <td>fyi forwarded by lauri a allen hou ect on 12 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Message ID                            Subject  \\\n",
       "0           0  [christmas, tree, farm, pictures]   \n",
       "1           1           [vastar, resources, inc]   \n",
       "2           2  [calpine, daily, gas, nomination]   \n",
       "3           3                        [re, issue]   \n",
       "4           4     [meter, 7268, nov, allocation]   \n",
       "\n",
       "                                             Message Spam/Ham        Date  \\\n",
       "0                                                 []      ham  1999-12-10   \n",
       "1  [gary, production, from, the, high, island, la...      ham  1999-12-13   \n",
       "2          [calpine, daily, gas, nomination, 1, doc]      ham  1999-12-14   \n",
       "3  [fyi, see, note, below, already, done, stella,...      ham  1999-12-14   \n",
       "4  [fyi, forwarded, by, lauri, a, allen, hou, ect...      ham  1999-12-14   \n",
       "\n",
       "                                         Message_str  \n",
       "0                                                     \n",
       "1  gary production from the high island larger bl...  \n",
       "2                 calpine daily gas nomination 1 doc  \n",
       "3  fyi see note below already done stella forward...  \n",
       "4  fyi forwarded by lauri a allen hou ect on 12 1...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert list of words back to string for vectorization\n",
    "data['Message_str'] = data['Message'].apply(lambda x: ' '.join(x))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14cb20b9-1062-46ae-86f8-2d3cdc99cf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['Message_str'], data['Spam/Ham'], test_size=0.25, random_state=42)  # Ensures a reproducible split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68cda47f-bd95-4816-8bef-8417b8e10b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # Vectorize the text data into a Boolean feature matrix, considering only words that appear at least 5 times\n",
    "# vectorizer = CountVectorizer(binary=True, min_df=5)\n",
    "# X_train_transformed = vectorizer.fit_transform(X_train)\n",
    "# features = vectorizer.get_feature_names_out()\n",
    "\n",
    "# # Label encoding\n",
    "# y_train_encoded = (y_train == 'spam').astype(int)\n",
    "\n",
    "# # Compute mutual information between each feature and the labels\n",
    "# mi_scores = mutual_info_classif(X_train_transformed, y_train_encoded, discrete_features=True)\n",
    "\n",
    "# # Create a Series to view feature scores\n",
    "# mi_scores_series = pd.Series(mi_scores, index=features)\n",
    "\n",
    "# # Sort the features by their mutual information score in descending order\n",
    "# sorted_features = mi_scores_series.sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93039bfe-7419-497b-9031-f194cd5c71ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_train_transformed[:1])\n",
    "# features = vectorizer.get_feature_names_out()\n",
    "# # To see the actual words corresponding to a few indices:\n",
    "# print(features[33193], features[36289], features[15832])\n",
    "# testing = X_train_transformed.toarray()\n",
    "# testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26efa7d3-c96e-4d6c-8a40-7aab926a205d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # X_train.head()\n",
    "# y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26974b59-d691-4f56-9ae5-e241b3b70058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_3000 = sorted_features.head(3000)\n",
    "# print(\"\\nTop 3000 features by information gain:\")\n",
    "# print(top_3000.head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4c73b64-59a6-4880-a7dc-2583b76b98b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words in the vocabulary:\n",
      "['enron' 'cc' 'pm' '2001' 'ect' 'subject' 'hou' 'forwarded' '2000' 'vince'\n",
      " 'thanks' 'am' 'attached' '713' 'http' 'kaminski' 'houston' 'questions'\n",
      " 'let' 'me' 'louise' '01' 'corp' 'gas' '02']\n"
     ]
    }
   ],
   "source": [
    "# If you need to load this vocabulary later, you can use:\n",
    "top_vocab = np.load('top_vocab.npy', allow_pickle=True)\n",
    "print(\"Top words in the vocabulary:\")\n",
    "print(top_vocab[:25])  # Print the top 25 words to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "496d5547-5660-4d5a-b872-c7919d7b5c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(top_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c4f62a6-f57f-4195-90e7-4ec50b696f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.63 s, sys: 22.2 ms, total: 1.66 s\n",
      "Wall time: 1.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Vectorize the text data into a Boolean feature matrix, considering only words that appear at least 5 times\n",
    "vectorizer = CountVectorizer(binary=True, min_df=5, vocabulary=top_vocab)\n",
    "X_train_transformed = vectorizer.fit_transform(X_train)\n",
    "features = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Label encoding\n",
    "y_train_encoded = (y_train == 'spam').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3042992-ecc4-4773-841f-bf2914091bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of Ham (based on training data): 0.49143828844861\n",
      "Probability of Spam (based on training data): 0.5085617115513901\n"
     ]
    }
   ],
   "source": [
    "# Calculate category counts from the training labels only\n",
    "category_counts = y_train.value_counts()\n",
    "\n",
    "# Calculate the total number of messages in the training set\n",
    "total_messages_train = len(y_train)\n",
    "\n",
    "# Calculate the a priori probabilities based on training data\n",
    "p_ham = category_counts['ham'] / total_messages_train\n",
    "p_spam = category_counts['spam'] / total_messages_train\n",
    "\n",
    "# Print the probabilities based on the training set\n",
    "print(f\"Probability of Ham (based on training data): {p_ham}\")\n",
    "print(f\"Probability of Spam (based on training data): {p_spam}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35fbf007-15ad-4123-a40f-20a8da07c22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually calculating probability of each feature given a class\n",
    "def calculate_feature_probabilities(X, y):\n",
    "    n_samples, n_features = X.shape\n",
    "    # Initialize dictionaries to hold probabilities\n",
    "    spam_probabilities = np.zeros(n_features)\n",
    "    ham_probabilities = np.zeros(n_features)\n",
    "    \n",
    "    # Total messages in each class\n",
    "    spam_count = np.sum(y == 1)\n",
    "    ham_count = np.sum(y == 0)\n",
    "    \n",
    "    # Calculate probabilities for each feature\n",
    "    for feature_index in range(n_features):\n",
    "        # Count occurrences of each feature in spam and ham messages\n",
    "        feature_spam_count = np.sum(X[y == 1, feature_index])\n",
    "        feature_ham_count = np.sum(X[y == 0, feature_index])\n",
    "        \n",
    "        # Apply Laplace smoothing\n",
    "        spam_probabilities[feature_index] = (feature_spam_count + 1) / (spam_count + 2)\n",
    "        ham_probabilities[feature_index] = (feature_ham_count + 1) / (ham_count + 2)\n",
    "    \n",
    "    return spam_probabilities, ham_probabilities\n",
    "\n",
    "# Prediction function using the Naive Bayes formula\n",
    "def predict(X, spam_probabilities, ham_probabilities, p_spam, p_ham):\n",
    "    n_samples, n_features = X.shape\n",
    "    predictions = []\n",
    "    for i in range(n_samples):\n",
    "        # Log probabilities to avoid underflow\n",
    "        spam_log_prob = np.log(p_spam)\n",
    "        ham_log_prob = np.log(p_ham)\n",
    "        \n",
    "        for feature_index in range(n_features):\n",
    "            if X[i, feature_index] == 1:  # Feature is present\n",
    "                spam_log_prob += np.log(spam_probabilities[feature_index])\n",
    "                ham_log_prob += np.log(ham_probabilities[feature_index])\n",
    "            else:  # Feature is absent\n",
    "                spam_log_prob += np.log(1 - spam_probabilities[feature_index])\n",
    "                ham_log_prob += np.log(1 - ham_probabilities[feature_index])\n",
    "        \n",
    "        # Compare probabilities\n",
    "        if spam_log_prob > ham_log_prob:\n",
    "            predictions.append(1)  # Spam\n",
    "        else:\n",
    "            predictions.append(0)  # Ham\n",
    "            \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8ce5c08-9761-4703-a8ab-c716fddd1443",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed = X_train_transformed.toarray()\n",
    "y_train_encoded = y_train_encoded.to_numpy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cabc61b0-752d-439e-a207-1ef6b5cf7e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate feature probabilities\n",
    "spam_probabilities, ham_probabilities = calculate_feature_probabilities(X_train_transformed, y_train_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518f9794-2b12-45ce-af7a-fccf91ed754a",
   "metadata": {},
   "source": [
    "### Train Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "181e78aa-cc82-4607-8752-1aaa82e596ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9420\n",
      "Confusion Matrix:\n",
      "[[11056  1371]\n",
      " [   96 12764]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Ham       0.99      0.89      0.94     12427\n",
      "        Spam       0.90      0.99      0.95     12860\n",
      "\n",
      "    accuracy                           0.94     25287\n",
      "   macro avg       0.95      0.94      0.94     25287\n",
      "weighted avg       0.95      0.94      0.94     25287\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prediction (using a subset of data to demonstrate)\n",
    "predictions = predict(X_train_transformed, spam_probabilities, ham_probabilities, p_spam, p_ham)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_train_encoded, predictions)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Generate a confusion matrix\n",
    "conf_matrix = confusion_matrix(y_train_encoded, predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Detailed classification report\n",
    "class_report = classification_report(y_train_encoded, predictions, target_names=['Ham', 'Spam'])\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35827ab3-f8d3-4c60-bb74-9458138e4ee2",
   "metadata": {},
   "source": [
    "### Test Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fae1dadf-a1e7-497f-a612-83ebc459fca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9394\n",
      "Test Confusion Matrix:\n",
      "[[3647  471]\n",
      " [  40 4271]]\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Ham       0.99      0.89      0.93      4118\n",
      "        Spam       0.90      0.99      0.94      4311\n",
      "\n",
      "    accuracy                           0.94      8429\n",
      "   macro avg       0.94      0.94      0.94      8429\n",
      "weighted avg       0.94      0.94      0.94      8429\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Transform the test data\n",
    "X_test_transformed = vectorizer.transform(X_test).toarray()\n",
    "\n",
    "# Predict on the test data\n",
    "test_predictions = predict(X_test_transformed, spam_probabilities, ham_probabilities, p_spam, p_ham)\n",
    "\n",
    "# Calculate accuracy and other metrics for the test set\n",
    "test_accuracy = accuracy_score((y_test == 'spam').astype(int), test_predictions)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Test set confusion matrix\n",
    "test_conf_matrix = confusion_matrix((y_test == 'spam').astype(int), test_predictions)\n",
    "print(\"Test Confusion Matrix:\")\n",
    "print(test_conf_matrix)\n",
    "\n",
    "# Test set classification report\n",
    "test_class_report = classification_report((y_test == 'spam').astype(int), test_predictions, target_names=['Ham', 'Spam'])\n",
    "print(\"Test Classification Report:\")\n",
    "print(test_class_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cde630c-34a8-434f-9ac6-c20a14aec21b",
   "metadata": {},
   "source": [
    "## Top Method words = .9394 Test Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74bc337-57e2-463e-b420-b13da76698ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
